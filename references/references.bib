
@article{ibraheem_understanding_2012,
	title = {Understanding {Color} {Models}: {A} {Review}},
	volume = {2},
	issn = {2225-7217},
	abstract = {Colors are important for human for communicating with the daily encountered objects as well as his species, these colors should be represented formally and numerically within a mathematical formula so it can be projected on device/ computer storage and applications, this mathematical representation is known as color model that can hold the color space, by the means of color’s primary components (Red, Green, and Blue) the computer can visualizes what the human does in hue and lightness. In this paper; a review of most popular color models are given with the explanation of the components, color system, and transformation formula for each other, application areas and usages are also included in this work with the classification of color models according to its dependence and independence on the hardware device used in specific application, a summary of the advantages and disadvantages of the color models are also demonstrated in this work.},
	language = {en},
	number = {3},
	author = {Ibraheem, Noor A and Hasan, Mokhtar M and Khan, Rafiqul Z and Mishra, Pramod K},
	year = {2012},
	file = {Ibraheem et al. - 2012 - Understanding Color Models A Review.pdf:files/1/Ibraheem et al. - 2012 - Understanding Color Models A Review.pdf:application/pdf},
}

@incollection{hura_image_2021,
	address = {Singapore},
	title = {Image {Colorization} with {Deep} {Convolutional} {Neural} {Networks}},
	volume = {668},
	isbn = {9789811553400 9789811553417},
	url = {http://link.springer.com/10.1007/978-981-15-5341-7_4},
	abstract = {We present a convolutional-neural-network-based system that faithfully colorizes black and white photographic images without direct human assistance. We explore various network architectures, objectives, color spaces, and problem formulations. The ﬁnal classiﬁcation-based model we build generates colorized images that are signiﬁcantly more aesthetically-pleasing than those created by the baseline regression-based model, demonstrating the viability of our methodology and revealing promising avenues for future work.},
	language = {en},
	urldate = {2023-02-14},
	booktitle = {Advances in {Communication} and {Computational} {Technology}},
	publisher = {Springer Singapore},
	author = {Pahal, Sudesh and Sehrawat, Preeti},
	editor = {Hura, Gurdeep Singh and Singh, Ashutosh Kumar and Siong Hoe, Lau},
	year = {2021},
	doi = {10.1007/978-981-15-5341-7_4},
	note = {Series Title: Lecture Notes in Electrical Engineering},
	pages = {45--56},
	file = {Pahal and Sehrawat - 2021 - Image Colorization with Deep Convolutional Neural .pdf:files/3/Pahal and Sehrawat - 2021 - Image Colorization with Deep Convolutional Neural .pdf:application/pdf},
}

@inproceedings{yoo_coloring_2019,
	address = {Long Beach, CA, USA},
	title = {Coloring {With} {Limited} {Data}: {Few}-{Shot} {Colorization} via {Memory} {Augmented} {Networks}},
	isbn = {978-1-72813-293-8},
	shorttitle = {Coloring {With} {Limited} {Data}},
	url = {https://ieeexplore.ieee.org/document/8953467/},
	doi = {10.1109/CVPR.2019.01154},
	abstract = {Despite recent advancements in deep learning-based automatic colorization, they are still limited when it comes to few-shot learning. Existing models require a signiﬁcant amount of training data. To tackle this issue, we present a novel memory-augmented colorization model MemoPainter that can produce high-quality colorization with limited data. In particular, our model is able to capture rare instances and successfully colorize them. We also propose a novel threshold triplet loss that enables unsupervised training of memory networks without the need of class labels. Experiments show that our model has superior quality in both few-shot and one-shot colorization tasks.},
	language = {en},
	urldate = {2023-02-14},
	booktitle = {2019 {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Yoo, Seungjoo and Bahng, Hyojin and Chung, Sunghyo and Lee, Junsoo and Chang, Jaehyuk and Choo, Jaegul},
	month = jun,
	year = {2019},
	pages = {11275--11284},
	file = {Yoo et al. - 2019 - Coloring With Limited Data Few-Shot Colorization .pdf:files/5/Yoo et al. - 2019 - Coloring With Limited Data Few-Shot Colorization .pdf:application/pdf},
}

@inproceedings{vitoria_chromagan_2020,
	address = {Snowmass Village, CO, USA},
	title = {{ChromaGAN}: {Adversarial} {Picture} {Colorization} with {Semantic} {Class} {Distribution}},
	isbn = {978-1-72816-553-0},
	shorttitle = {{ChromaGAN}},
	url = {https://ieeexplore.ieee.org/document/9093389/},
	doi = {10.1109/WACV45572.2020.9093389},
	abstract = {The colorization of grayscale images is an ill-posed problem, with multiple correct solutions. In this paper, we propose an adversarial learning colorization approach coupled with semantic information. A generative network is used to infer the chromaticity of a given grayscale image conditioned to semantic clues. This network is framed in an adversarial model that learns to colorize by incorporating perceptual and semantic understanding of color and class distributions. The model is trained via a fully selfsupervised strategy. Qualitative and quantitative results show the capacity of the proposed method to colorize images in a realistic way achieving state-of-the-art results.},
	language = {en},
	urldate = {2023-02-14},
	booktitle = {2020 {IEEE} {Winter} {Conference} on {Applications} of {Computer} {Vision} ({WACV})},
	publisher = {IEEE},
	author = {Vitoria, Patricia and Raad, Lara and Ballester, Coloma},
	month = mar,
	year = {2020},
	pages = {2434--2443},
	file = {Vitoria et al. - 2020 - ChromaGAN Adversarial Picture Colorization with S.pdf:files/7/Vitoria et al. - 2020 - ChromaGAN Adversarial Picture Colorization with S.pdf:application/pdf},
}

@article{joshi_auto-colorization_2020,
	title = {Auto-{Colorization} of {Historical} {Images} {Using} {Deep} {Convolutional} {Neural} {Networks}},
	volume = {8},
	issn = {2227-7390},
	url = {https://www.mdpi.com/2227-7390/8/12/2258},
	doi = {10.3390/math8122258},
	abstract = {Enhancement of Cultural Heritage such as historical images is very crucial to safeguard the diversity of cultures. Automated colorization of black and white images has been subject to extensive research through computer vision and machine learning techniques. Our research addresses the problem of generating a plausible colored photograph of ancient, historically black, and white images of Nepal using deep learning techniques without direct human intervention. Motivated by the recent success of deep learning techniques in image processing, a feed-forward, deep Convolutional Neural Network (CNN) in combination with Inception- ResnetV2 is being trained by sets of sample images using back-propagation to recognize the pattern in RGB and grayscale values. The trained neural network is then used to predict two a* and b* chroma channels given grayscale, L channel of test images. CNN vividly colorizes images with the help of the fusion layer accounting for local features as well as global features. Two objective functions, namely, Mean Squared Error (MSE) and Peak Signal-to-Noise Ratio (PSNR), are employed for objective quality assessment between the estimated color image and its ground truth. The model is trained on the dataset created by ourselves with 1.2 K historical images comprised of old and ancient photographs of Nepal, each having 256 × 256 resolution. The loss i.e., MSE, PSNR, and accuracy of the model are found to be 6.08\%, 34.65 dB, and 75.23\%, respectively. Other than presenting the training results, the public acceptance or subjective validation of the generated images is assessed by means of a user study where the model shows 41.71\% of naturalness while evaluating colorization results.},
	language = {en},
	number = {12},
	urldate = {2023-02-14},
	journal = {Mathematics},
	author = {Joshi, Madhab Raj and Nkenyereye, Lewis and Joshi, Gyanendra Prasad and Islam, S. M. Riazul and Abdullah-Al-Wadud, Mohammad and Shrestha, Surendra},
	month = dec,
	year = {2020},
	pages = {2258},
	file = {Joshi et al. - 2020 - Auto-Colorization of Historical Images Using Deep .pdf:files/8/Joshi et al. - 2020 - Auto-Colorization of Historical Images Using Deep .pdf:application/pdf},
}

@misc{zhang_colorful_2016,
	title = {Colorful {Image} {Colorization}},
	url = {http://arxiv.org/abs/1603.08511},
	abstract = {Given a grayscale photograph as input, this paper attacks the problem of hallucinating a plausible color version of the photograph. This problem is clearly underconstrained, so previous approaches have either relied on signiﬁcant user interaction or resulted in desaturated colorizations. We propose a fully automatic approach that produces vibrant and realistic colorizations. We embrace the underlying uncertainty of the problem by posing it as a classiﬁcation task and use class-rebalancing at training time to increase the diversity of colors in the result. The system is implemented as a feed-forward pass in a CNN at test time and is trained on over a million color images. We evaluate our algorithm using a “colorization Turing test,” asking human participants to choose between a generated and ground truth color image. Our method successfully fools humans on 32\% of the trials, signiﬁcantly higher than previous methods. Moreover, we show that colorization can be a powerful pretext task for self-supervised feature learning, acting as a cross-channel encoder. This approach results in state-of-the-art performance on several feature learning benchmarks.},
	language = {en},
	urldate = {2023-02-14},
	publisher = {arXiv},
	author = {Zhang, Richard and Isola, Phillip and Efros, Alexei A.},
	month = oct,
	year = {2016},
	note = {arXiv:1603.08511 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Zhang et al. - 2016 - Colorful Image Colorization.pdf:files/9/Zhang et al. - 2016 - Colorful Image Colorization.pdf:application/pdf},
}

@article{brachman_synthesis_nodate,
	title = {Synthesis {Lectures} on {Artiﬁcial} {Intelligence} and {Machine} {Learning}},
	language = {en},
	author = {Brachman, Ronald J and Stone, Peter},
	file = {Brachman and Stone - Synthesis Lectures on Artiﬁcial Intelligence and M.pdf:files/13/Brachman and Stone - Synthesis Lectures on Artiﬁcial Intelligence and M.pdf:application/pdf},
}

@article{fu_distributive_1995,
	title = {Distributive properties of main overlap and noise terms in {Autoassociative} {Memory} {Networks}},
	volume = {8},
	issn = {08936080},
	url = {https://linkinghub.elsevier.com/retrieve/pii/089360809400081V},
	doi = {10.1016/0893-6080(94)00081-V},
	abstract = {The distributive properties of both main overlap and noise terms of an autoassociative memory network are analyzed with computer simulations. Some interesting statistical properties of the main overlap and noises have been exposed. The results provide an important basis for the establishment of a mathematical model that is capable of describing the dynamics of the neural network.},
	language = {en},
	number = {3},
	urldate = {2023-02-14},
	journal = {Neural Networks},
	author = {Fu, Alan M.N. and Yan, Hong},
	month = jan,
	year = {1995},
	pages = {405--410},
	file = {Fu and Yan - 1995 - Distributive properties of main overlap and noise .pdf:files/15/Fu and Yan - 1995 - Distributive properties of main overlap and noise .pdf:application/pdf},
}

@article{pavia_giving_nodate,
	title = {Giving life to the past: colourisation of historical black and white photographs using deep learning techniques.},
	language = {en},
	author = {Pavia, Matthew},
	file = {Pavia - Giving life to the past colourisation of historic.pdf:files/17/Pavia - Giving life to the past colourisation of historic.pdf:application/pdf},
}
